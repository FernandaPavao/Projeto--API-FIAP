# **Analysis Report ‚Äî Experimentos LSTM**

Este relat√≥rio resume, interpreta e avalia os experimentos realizados para previs√£o de s√©ries temporais usando redes LSTM. Os resultados foram extra√≠dos diretamente do arquivo `experiment_log.csv`.

---

## **1. Resumo dos Experimentos**

Foram conduzidos **4 experimentos**, variando unidades dos LSTMs, taxa de dropout, batch size e learning rate.

### **Tabela Resumo**

| Experimento       | units1 | units2 | dropout | batch | lr     | epochs | MAE      | RMSE     | MAPE     | Notes                    |
|------------------|--------|--------|---------|-------|--------|--------|----------|----------|----------|--------------------------|
| Baseline          | 50     | 50     | 0.2     | 32    | 0.001  | 56     | **0.8351** | **1.0834** | **1.54%** | Baseline LSTM model      |
| Bigger Model      | 128    | 64     | 0.2     | 64    | 0.001  | 22     | 1.8564   | 2.3256   | 3.37%    | Bigger Model             |
| Smaller LR        | 128    | 64     | 0.2     | 64    | 0.0005 | 52     | 0.8610   | 1.1912   | 1.64%    | Smaller Learning Rate    |
| More Dropout      | 128    | 64     | 0.3     | 64    | 0.001  | 76     | **0.7487** | **0.9701** | **1.39%** | More Dropout             |

---

## **2. Interpreta√ß√£o Geral dos Resultados**

### üîπ **Desempenho Global**

- O experimento **More Dropout** apresentou a **melhor performance geral**, com:
  - **Menor MAE** ‚Üí 0.7487  
  - **Menor RMSE** ‚Üí 0.9701  
  - **Menor MAPE** ‚Üí 1.39%

  Aumentar o dropout reduziu overfitting e estabilizou as previs√µes.

- O modelo **Bigger Model (128 ‚Üí 64)** foi o pior, provavelmente por **overfitting severo** devido √† complexidade excessiva.

- O **Baseline** teve desempenho muito s√≥lido. Um modelo relativamente simples funciona bem para este dataset.

- O **Smaller LR** teve boa estabilidade, mas n√£o superou o modelo com maior dropout.

---

## **3. Ranking dos Modelos**

### ü•á **1¬∫ Lugar ‚Äî More Dropout**
- Melhor erro absoluto, quadr√°tico e percentual.
- Modelo mais robusto e com melhor generaliza√ß√£o.

### ü•à **2¬∫ Lugar ‚Äî Baseline**
- Desempenho forte com arquitetura simples.
- √ìtimo ponto de partida para itera√ß√µes futuras.

### ü•â **3¬∫ Lugar ‚Äî Smaller LR**
- Bom resultado, mas n√£o supera os dois primeiros.

### ‚ùå **4¬∫ Lugar ‚Äî Bigger Model**
- Maior erro.
- Indica√ß√£o clara de overfitting.

---

## **4. An√°lise dos Hiperpar√¢metros**

### **Tamanho da Rede**
Modelos com muitas unidades (128‚Üí64) **n√£o melhoraram** e tiveram pior desempenho.

### **Dropout**
O aumento de dropout para **0.3** foi crucial para melhorar generaliza√ß√£o.

### **Learning Rate**
- LR menor (0.0005) ajudou na estabilidade, mas n√£o superou ajuste de dropout.

### **Batch Size**
Tanto 32 quanto 64 funcionaram bem; 64 convergiu levemente mais r√°pido.

---

## **5. Conclus√£o**

O modelo **More Dropout** √© o melhor experimento at√© agora e deve ser utilizado como **modelo principal**.

Ele apresentou:
- Melhor erro absoluto  
- Melhor generaliza√ß√£o  
- Maior robustez  
- Converg√™ncia est√°vel  

A arquitetura simples do baseline tamb√©m se mostrou surpreendentemente efetiva.

---

