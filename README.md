# Tech Challenge Fase 4 - PrevisÃ£o de AÃ§Ãµes com LSTM

**Disciplina:** Machine Learning Engineering  
**Projeto:** PrevisÃ£o de preÃ§os de aÃ§Ãµes usando Deep Learning (LSTM)  
**Empresa Analisada:** Vale S.A. (VALE3.SA)

---

## ğŸ“‹ Ãndice

- [Sobre o Projeto](#sobre-o-projeto)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Requisitos](#requisitos)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [Como Executar](#como-executar)
- [DescriÃ§Ã£o dos Scripts](#descriÃ§Ã£o-dos-scripts)
- [Dados Gerados](#dados-gerados)
- [VisualizaÃ§Ãµes](#visualizaÃ§Ãµes)
- [PrÃ³ximos Passos](#prÃ³ximos-passos)
- [Treinamento do Modelo LSTM](#treinamento-do-modelo-lstm)
- [Experimentos Realizados](#experimentos-realizados)
- [Artefatos Gerados](#artefatos-gerados)
- [Scripts Complementares](#scripts-complementares)
- [RelatÃ³rios e AnÃ¡lises](#relatÃ³rios-e-anÃ¡lises)

---

## ğŸ¯ Sobre o Projeto

Este projeto implementa um pipeline completo de Machine Learning para previsÃ£o de preÃ§os de aÃ§Ãµes utilizando redes neurais LSTM (Long Short-Term Memory). 

O trabalho envolve:

1. Coleta e prÃ©-processamento de dados
2. PreparaÃ§Ã£o dos dados para modelos sequenciais
3. Desenvolvimento, treinamento e avaliaÃ§Ã£o de modelos LSTM
4. GeraÃ§Ã£o de artefatos de modelo, experimentos e relatÃ³rios


### CaracterÃ­sticas do Dataset

- **Ativo:** VALE3.SA (Vale do Rio Doce)
- **PerÃ­odo:** Ãšltimos 5 anos
- **FrequÃªncia:** DiÃ¡ria
- **Features:** 
  - BÃ¡sicas: Open, High, Low, Close, Volume
  - Indicadores TÃ©cnicos: SMA, EMA, RSI, MACD, Bollinger Bands, Volatilidade
- **Janela Temporal:** 60 dias (lookback)
- **DivisÃ£o:** 70% treino / 15% validaÃ§Ã£o / 15% teste
  ----
## API em ProduÃ§Ã£o

- URL base: https://projeto-api-fiap-xqxb.onrender.com
- DocumentaÃ§Ã£o (Swagger): https://projeto-api-fiap-xqxb.onrender.com/docs

### Endpoint de previsÃ£o

**POST** `/predict`

**Request (JSON)**

```json
{
  "data": [
    [ ... 19 nÃºmeros ... ],
    ...
  ]
}

---

## ğŸ“ Estrutura do Projeto

```
tech_challenge_fase4/
â”‚
â”œâ”€â”€ api/                   
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ schemas.py
â”‚   â”‚   â””â”€â”€ services.py
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ model.keras
â”‚   â”‚   â””â”€â”€ scaler.pkl
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile

â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ â† Dados Brutos do yFinance
â”‚ â”‚ â””â”€â”€ VALE3_SA_raw.csv
â”‚ â””â”€â”€ processed/ â† Dados Processados e prontos para treino
â”‚ â”œâ”€â”€ VALE3_SA_processed.csv
â”‚ â”œâ”€â”€ scaler.pkl â† Scaler para normalizaÃ§Ã£o
â”‚ â”œâ”€â”€ train_data.npz â† Dados de treino (X, y)
â”‚ â”œâ”€â”€ val_data.npz â† Dados de validaÃ§Ã£o (X, y)
â”‚ â”œâ”€â”€ test_data.npz â† Dados de teste (X, y)
â”‚ â””â”€â”€ data_info.json â† Metadados do dataset
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ config.py  â† ConfiguraÃ§Ã£o do projeto
â”‚ â”œâ”€â”€ data_collection.py â† Script de coleta de dados
â”‚ â”œâ”€â”€ data_preprocessing.py â† Script de prÃ©-processamento
â”‚ â”œâ”€â”€ data_preparation.py â† Script de preparaÃ§Ã£o para LSTM
â”‚ â”œâ”€â”€ train_model.py â† Treinamento do modelo LSTM
â”‚ â”œâ”€â”€ test_model.py â† AvaliaÃ§Ã£o do modelo
â”‚ â”œâ”€â”€ eda_analysis.py â† AnÃ¡lise exploratÃ³ria dos dados
â”‚ â””â”€â”€ plot_experiments.py â† VisualizaÃ§Ã£o de experimentos
â”‚ 
â”‚
â”œâ”€â”€ models/ 
â”‚ â””â”€â”€  best_model.keras â† Melhor modelo
â”œâ”€â”€ results/
â”‚ â”œâ”€â”€ metrics.json
â”‚ â”œâ”€â”€ metrics_test.json
â”‚ â”œâ”€â”€ predictions.csv
â”‚ â”œâ”€â”€ pred_vs_real.png
â”‚ â”œâ”€â”€ error_distribution.png
â”‚ â”œâ”€â”€ experiment_log.csv
â”‚ â”œâ”€â”€ experiment_rank_plot.png
â”‚ â”œâ”€â”€ experiment_summary.png
â”‚ â”œâ”€â”€ history.pkl
â”‚ â””â”€â”€ analysis_report.md
â”‚
â”œâ”€â”€ reports/
â”‚ â””â”€â”€ figures/
â”‚ â”œâ”€â”€ 01_price_history.png
â”‚ â”œâ”€â”€ 02_returns_distribution.png
â”‚ â”œâ”€â”€ 03_moving_averages.png
â”‚ â”œâ”€â”€ 04_technical_indicators.png
â”‚ â”œâ”€â”€ 05_correlation_matrix.png
â”‚ â””â”€â”€ summary_statistics.txt
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ run_pipeline.py
```

---

## ğŸ”§ Requisitos

- Python 3.8 ou superior
- Bibliotecas listadas em `requirements.txt`

---

## ğŸ“¦ InstalaÃ§Ã£o

### 1. Clone ou baixe o projeto

```bash
git clone <seu-repositorio>
cd tech_challenge_fase4
```

### 2. Crie um ambiente virtual (recomendado)

**Windows:**
```bash
python -m venv venv
venv\Scripts\activate
```

**Linux/Mac:**
```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

---

## ğŸš€ Como Executar

### OpÃ§Ã£o 1: Executar todo o pipeline de uma vez

```bash
python run_pipeline.py
```

Este script executa automaticamente:
1. Coleta de dados
2. PrÃ©-processamento
3. PreparaÃ§Ã£o para LSTM
4. AnÃ¡lise exploratÃ³ria (EDA)

### OpÃ§Ã£o 2: Executar scripts individualmente

#### Passo 1: Coletar dados

```bash
python src/data_collection.py
```

**O que faz:**
- Baixa dados histÃ³ricos da VALE3.SA usando yfinance
- Valida os dados coletados
- Salva em `data/raw/VALE3_SA_raw.csv`

#### Passo 2: PrÃ©-processar dados

```bash
python src/data_preprocessing.py
```

**O que faz:**
- Remove valores nulos
- Detecta e trata outliers
- Adiciona indicadores tÃ©cnicos (SMA, EMA, RSI, MACD, Bollinger Bands)
- Salva em `data/processed/VALE3_SA_processed.csv`

#### Passo 3: Preparar dados para LSTM

```bash
python src/data_preparation.py
```

**O que faz:**
- Normaliza os dados com MinMaxScaler
- Cria sequÃªncias temporais (janelas de 60 dias)
- Divide em treino/validaÃ§Ã£o/teste (70/15/15)
- Salva arquivos `.npz` prontos para treino

#### Passo 4: AnÃ¡lise ExploratÃ³ria (Opcional)

```bash
python src/eda_analysis.py
```

**O que faz:**
- Gera grÃ¡ficos de anÃ¡lise
- Cria estatÃ­sticas descritivas
- Salva visualizaÃ§Ãµes em `reports/figures/`

#### Passo 5: Treinamento do modelo LSTM

```bash
python ./src/train_model.py
```
#### Passo 6: Teste e avaliaÃ§Ã£o do modelo

```bash
python ./src/test_model.py
```

#### Passo 7: Plot dos experimentos

```bash
python ./src/plot_experiments.py
```
---

## ğŸš€ API de PrevisÃ£o com LSTM 

Esta seÃ§Ã£o descreve a camada de serving e deploy do modelo LSTM treinado,
responsÃ¡vel por disponibilizar o modelo como um serviÃ§o de API RESTful.

A API foi desenvolvida seguindo boas prÃ¡ticas de Machine Learning Engineering,
com separaÃ§Ã£o clara entre a etapa de treinamento do modelo e a etapa de inferÃªncia
em produÃ§Ã£o.

### ğŸ¯ Objetivo da API

- Servir o modelo LSTM treinado via API
- Receber janelas temporais de sÃ©ries histÃ³ricas
- Validar formato e dimensionalidade dos dados
- Aplicar o scaler utilizado no treinamento
- Retornar a previsÃ£o do prÃ³ximo valor do ativo

### ğŸ§± Arquitetura da API

- **Framework:** FastAPI
- **Modelo:** LSTM treinado (Keras `.keras`)
- **Scaler:** MinMaxScaler (`.pkl`)
- **Entrada:** 60 timesteps Ã— 19 features
- **SaÃ­da:** PrevisÃ£o do prÃ³ximo valor do preÃ§o

### ğŸ“ LocalizaÃ§Ã£o no Projeto

A API estÃ¡ localizada na pasta `api/` do projeto, mantendo separaÃ§Ã£o clara entre
treinamento do modelo e inferÃªncia em produÃ§Ã£o.

### â–¶ï¸ ExecuÃ§Ã£o da API

```bash
cd api
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
uvicorn app.main:app --host 127.0.0.1 --port 8001

http://127.0.0.1:8001/docs




### ğŸ³ Docker

O projeto inclui um Dockerfile preparado para containerizaÃ§Ã£o da API.
A execuÃ§Ã£o via Docker depende de Docker Desktop, WSL 2 e virtualizaÃ§Ã£o ativa.
Em ambientes corporativos, essa execuÃ§Ã£o pode ser restrita.



## ğŸ“Š DescriÃ§Ã£o dos Scripts

### `config.py`
Centraliza todas as configuraÃ§Ãµes do projeto:
- ParÃ¢metros da coleta de dados
- ConfiguraÃ§Ãµes do modelo (lookback, features)
- DivisÃ£o dos dados
- Caminhos de arquivos

### `data_collection.py`
ResponsÃ¡vel pela coleta de dados:
- Usa biblioteca `yfinance` para baixar dados histÃ³ricos
- Valida integridade dos dados
- Detecta valores nulos, negativos e duplicados

### `data_preprocessing.py`
Realiza limpeza e engenharia de features:
- Tratamento de valores ausentes (interpolaÃ§Ã£o)
- RemoÃ§Ã£o/tratamento de outliers (mÃ©todo IQR)
- AdiÃ§Ã£o de 15+ indicadores tÃ©cnicos
- ValidaÃ§Ã£o final dos dados

### `data_preparation.py`
Prepara dados especificamente para LSTM:
- NormalizaÃ§Ã£o com MinMaxScaler [0, 1]
- CriaÃ§Ã£o de sequÃªncias temporais (janelas deslizantes)
- DivisÃ£o temporal em treino/validaÃ§Ã£o/teste
- Salva dados em formato otimizado (`.npz`)

### `eda_analysis.py`
AnÃ¡lise exploratÃ³ria completa:
- HistÃ³rico de preÃ§os e volume
- DistribuiÃ§Ã£o de retornos
- MÃ©dias mÃ³veis e indicadores tÃ©cnicos
- Matriz de correlaÃ§Ã£o
- EstatÃ­sticas descritivas

### `train_model.py`
Treina e salva o modelo:
- Carrega dados e scaler
- Cria e treina o modelo LSTM
- Usa callbacks: EarlyStopping, ReduceLROnPlateau e ModelCheckpoint
- Salva:
   - best_model.keras
   - history.pkl
   - metrics.json
   - Registro no experiment_log.csv

### `test_model.py`
Testa e salva as mÃ©tricas e imagens:
- Carrega o modelo salvo.
- Realiza previsÃµes no conjunto de teste.
- Desnormaliza a saÃ­da.
- Gera:
   - predictions.csv
   - pred_vs_real.png
   - error_distribution.png
   - metrics_test.json

### `plot_experiments.py`
Compara os experimentos e rankeia eles:
- LÃª o experiments_log.csv
- Plota ranking dos modelos
- Gera:
   - experiment_rank_plot.png
   - experiment_summary.png

---

## ğŸ’¾ Dados Gerados

Os seguintes arquivos estÃ£o prontos para uso no treinamento do modelo LSTM:

1. **`train_data.npz`**
   - `X_train`: shape (n_samples, 60, n_features)
   - `y_train`: shape (n_samples,)

2. **`val_data.npz`**
   - `X_val`: shape (n_samples, 60, n_features)
   - `y_val`: shape (n_samples,)

3. **`test_data.npz`**
   - `X_test`: shape (n_samples, 60, n_features)
   - `y_test`: shape (n_samples,)

4. **`scaler.pkl`**
   - Objeto MinMaxScaler salvo com pickle
   - NecessÃ¡rio para desnormalizar as previsÃµes

5. **`data_info.json`**
   - Metadados do dataset (features, shapes, datas, etc.)

### Como carregar os dados

```python
import numpy as np
import pickle

# Carregar dados de treino
train_data = np.load('data/processed/train_data.npz')
X_train = train_data['X_train']
y_train = train_data['y_train']

# Carregar dados de validaÃ§Ã£o
val_data = np.load('data/processed/val_data.npz')
X_val = val_data['X_val']
y_val = val_data['y_val']

# Carregar dados de teste
test_data = np.load('data/processed/test_data.npz')
X_test = test_data['X_test']
y_test = test_data['y_test']

# Carregar scaler (para desnormalizar previsÃµes)
with open('data/processed/scaler.pkl', 'rb') as f:
    scaler = pickle.load(f)

# Exemplo de desnormalizaÃ§Ã£o
# predictions_original = scaler.inverse_transform(predictions_normalized)
```

---

## ğŸ“ˆ VisualizaÃ§Ãµes

ApÃ³s executar `eda_analysis.py`, os seguintes grÃ¡ficos sÃ£o gerados:

1. **01_price_history.png**: HistÃ³rico de preÃ§os e volume
2. **02_returns_distribution.png**: DistribuiÃ§Ã£o de retornos diÃ¡rios
3. **03_moving_averages.png**: PreÃ§o com mÃ©dias mÃ³veis
4. **04_technical_indicators.png**: RSI, MACD e Bollinger Bands
5. **05_correlation_matrix.png**: CorrelaÃ§Ã£o entre features
6. **summary_statistics.txt**: EstatÃ­sticas descritivas completas

---

## ğŸ“ ConfiguraÃ§Ãµes Importantes

### Modificar parÃ¢metros

Edite o arquivo `src/config.py` para alterar:

```python
# Ativo e perÃ­odo
STOCK_SYMBOL = "VALE3.SA"
START_DATE = '2019-10-17'  # AutomÃ¡tico: Ãºltimos 5 anos
END_DATE = '2024-10-17'    # AutomÃ¡tico: hoje

# Janela temporal
LOOKBACK_DAYS = 60  # Dias para "olhar" para trÃ¡s

# DivisÃ£o dos dados
TRAIN_SIZE = 0.70
VAL_SIZE = 0.15
TEST_SIZE = 0.15

# Indicadores tÃ©cnicos
ADD_TECHNICAL_INDICATORS = True
SMA_PERIODS = [7, 21, 50]
RSI_PERIOD = 14
```

---

### Arquitetura utilizada

Modelo LSTM Dropout maior

```python
LSTM(128, return_sequences=True)
Dropout(0.3)
BatchNormalization()
LSTM(64)
Dropout(0.3)
Dense(32, activation='relu')
Dense(1)

```
ParÃ¢metros do treinamento

- Optimizer: Adam
- Loss: MSE
- Batch size: 32â€“64
- Epochs: atÃ© 100
- Callbacks: EarlyStopping, ReduceLROnPlateau, ModelCheckpoint

MÃ©tricas utilizadas

- MAE
- RMSE
- MAPE

### Experimentos realizados

Os experimentos foram executados e documentados em:
   - results/experiment_log.csv
   - results/experiments_rank_lot.png
   - results/experiment_summary.png
   - results/analysis_report.md

## ğŸ› Troubleshooting

### Erro: "No module named 'yfinance'"
```bash
pip install yfinance
```

### Erro: "FileNotFoundError"
Execute os scripts na ordem correta:
1. `data_collection.py`
2. `data_preprocessing.py`
3. `data_preparation.py`

### Erro de data no yfinance
Verifique sua conexÃ£o com a internet. O yfinance precisa acessar o Yahoo Finance.

---

## ğŸ“š ReferÃªncias

- **yfinance**: https://pypi.org/project/yfinance/
- **LSTM**: https://colah.github.io/posts/2015-08-Understanding-LSTMs/
- **MinMaxScaler**: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html
- **Indicadores TÃ©cnicos**: https://github.com/bukosabino/ta

---

## âœ… Checklist de Entrega - Pessoa 1

- [x] Coleta de dados histÃ³ricos (yfinance)
- [x] Tratamento de valores nulos
- [x] DetecÃ§Ã£o e tratamento de outliers
- [x] NormalizaÃ§Ã£o com MinMaxScaler
- [x] AdiÃ§Ã£o de indicadores tÃ©cnicos
- [x] CriaÃ§Ã£o de janelas temporais (60 dias)
- [x] DivisÃ£o treino/validaÃ§Ã£o/teste (70/15/15)
- [x] Salvamento dos dados processados
- [x] DocumentaÃ§Ã£o completa
- [x] AnÃ¡lise exploratÃ³ria (EDA)
- [x] Scripts organizados e comentados

---
## âœ… Checklist de Entrega - Pessoa 3
- [x] Carregamento do modelo LSTM treinado (.keras)
- [x] Carregamento do scaler utilizado no treinamento (.pkl)
- [x] ImplementaÃ§Ã£o de API RESTful com FastAPI
- [x] ValidaÃ§Ã£o da entrada (timesteps e nÃºmero de features)
- [x] PrÃ©-processamento para inferÃªncia (scaling e reshape)
- [x] InferÃªncia do modelo e desnormalizaÃ§Ã£o da previsÃ£o
- [x] Tratamento de erros e respostas HTTP apropriadas
- [x] DocumentaÃ§Ã£o do endpoint `/predict`
- [x] EstruturaÃ§Ã£o da aplicaÃ§Ã£o em camada de API (`api/`)
- [x] CriaÃ§Ã£o de `requirements.txt` para inferÃªncia
- [x] CriaÃ§Ã£o de `Dockerfile` para containerizaÃ§Ã£o


## ğŸ‘¥ Autores

**Pessoa 1:** Coleta e PrÃ©-processamento dos Dados âœ…  
**Pessoa 2:** Desenvolvimento do Modelo LSTM  âœ…
**Pessoa 3:** Deploy da API  âœ…
**Pessoa 4:** ProduÃ§Ã£o e Monitoramento  

---

## ğŸ“„ LicenÃ§a

Este projeto foi desenvolvido para fins acadÃªmicos como parte do Tech Challenge da Fase 4.

---


**Ãšltima atualizaÃ§Ã£o:** Dezembro 2025
